# ğŸ¨ Image Color Correction with U-Net

This project implements a **U-Net-based deep learning model** for **image color correction**.  
It includes training, evaluation, and a **Streamlit web app** for easy inference.

---

## ğŸ“‚ Dataset
We used the **MIT-Adobe FiveK dataset** (custom split):  
ğŸ‘‰ [Dataset on Kaggle](https://www.kaggle.com/datasets/ahmedmohmedbalta/mitabovefivek)  

- **5000 RAW images**  
- **5000 color-corrected images** (aligned with RAW images)  

---

## ğŸš€ Features
- U-Net architecture with dropout & skip connections
- Mixed precision training with gradient clipping
- Early stopping and best model saving
- Streamlit app for inference (before/after comparison)
- TorchScript export for deployment

---

## ğŸ“‚ Project Structure
```
project_root/
â”œâ”€â”€ src/                    # Source code directory
â”‚   â”œâ”€â”€ models/            # Model definitions
â”‚   â”‚   â”œâ”€â”€ unet.py       # U-Net architecture
â”‚   â”‚   â””â”€â”€ blocks.py     # U-Net building blocks
â”‚   â”œâ”€â”€ utils/            # Utility functions
â”‚   â”‚   â””â”€â”€ transforms.py # Image transforms
â”‚   â””â”€â”€ app/             # Application code
â”‚       â””â”€â”€ main.py      # Streamlit application
â”œâ”€â”€ notebooks/            # Jupyter notebooks
â”‚   â””â”€â”€ Train_UNet.ipynb # Training notebook
â”œâ”€â”€ tests/               # Unit tests
â”œâ”€â”€ models/              # Saved model checkpoints
â”‚   â””â”€â”€ best_model-3.pth
â”œâ”€â”€ docs/                # Documentation
â”‚   â””â”€â”€ images/         # Documentation assets
â”œâ”€â”€ configs/            # Configuration files
â”œâ”€â”€ requirements.txt    # Dependencies
â””â”€â”€ setup.py           # Package setup
```

---

## ğŸ›  Installation
Clone the repository and install dependencies:
```bash
git clone https://github.com/Balta8/image-color-correction-unet.git
cd image-color-correction-unet

# Create environment (recommended: Python 3.10 or 3.11)
conda create -n unet python=3.11 -y
conda activate unet

# Install dependencies
pip install -r requirements.txt
```

---
## ğŸ§  Trained Model
The trained model can be downloaded from Google Drive:  
ğŸ‘‰ [Download Trained Model](https://drive.google.com/file/d/1nhhm6LbFb4JjO_VEt364W19eQVwGUBV5/view?usp=drive_link)   

âš ï¸ Place the model file (`best_model-3.pth`) inside the `models/` folder before running:

```bash
# Run the Streamlit app
streamlit run src/app/main.py
```
---
# Features:
- Upload a raw input image  
- Get corrected output side-by-side with the original  
- Option to download corrected image  
---

## ğŸ“· Example Results
| Raw Input | Corrected Output |
|---------------|---------------|
| ![raw](docs/images/raw_example.jpg) | ![corrected](docs/images/corrected_example.png) |

---

## ğŸ“Œ Notes
- Best model is saved as `best_model-3.pth`
- Large files (datasets, checkpoints) are ignored via `.gitignore`
- TorchScript version also available for deployment

---

## ğŸ‘¤ Author
Developed by **Ahmed Balta & Ahmed Elnashar**
